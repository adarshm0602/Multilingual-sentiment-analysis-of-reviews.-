{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transliteration Model Testing\n",
    "\n",
    "This notebook tests the Romanized Kannada to Kannada script transliteration functionality.\n",
    "\n",
    "## Contents\n",
    "1. Setup and Imports\n",
    "2. Basic Transliteration Tests\n",
    "3. Side-by-Side Comparison\n",
    "4. Accuracy Calculation with Reference Translations\n",
    "5. Error Pattern Analysis\n",
    "6. Visualization of Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Import project modules\n",
    "from src.preprocessing import Transliterator, TransliterationResult\n",
    "from src.preprocessing import LanguageDetector\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the transliterator\n",
    "transliterator = Transliterator()\n",
    "\n",
    "# Check status\n",
    "status = transliterator.get_status()\n",
    "print(\"Transliterator Status:\")\n",
    "for key, value in status.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Transliteration Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data: Romanized Kannada samples\n",
    "test_samples = [\n",
    "    # Greetings\n",
    "    \"namaskara\",\n",
    "    \"namaskara hegidira\",\n",
    "    \n",
    "    # Positive sentiments\n",
    "    \"tumba chennagide\",\n",
    "    \"ee product tumba olle\",\n",
    "    \"nanna ishta aagide\",\n",
    "    \"quality tumba chennagide\",\n",
    "    \n",
    "    # Negative sentiments\n",
    "    \"bekilla ee product\",\n",
    "    \"tumba ketta quality\",\n",
    "    \"sariyilla beda\",\n",
    "    \n",
    "    # Mixed/Neutral\n",
    "    \"ok agide\",\n",
    "    \"price tumba bele\",\n",
    "    \"delivery fast aagide\",\n",
    "    \n",
    "    # Questions\n",
    "    \"yenu price ide\",\n",
    "    \"elli sigatte\",\n",
    "    \"yaake delay aagide\",\n",
    "    \n",
    "    # Longer sentences\n",
    "    \"ee product tumba chennagide naanu recommend madtini\",\n",
    "    \"quality olle aadare price tumba bele\",\n",
    "]\n",
    "\n",
    "print(f\"Total test samples: {len(test_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform transliteration on all samples\n",
    "results = []\n",
    "\n",
    "for sample in test_samples:\n",
    "    result = transliterator.transliterate(sample)\n",
    "    results.append({\n",
    "        'input': sample,\n",
    "        'output': result.transliterated,\n",
    "        'method': result.method,\n",
    "        'word_count': len(sample.split()),\n",
    "        'mappings': result.word_mappings\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Transliteration completed!\")\n",
    "print(f\"Results shape: {results_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_comparison(df: pd.DataFrame, title: str = \"Transliteration Results\"):\n",
    "    \"\"\"\n",
    "    Display a formatted side-by-side comparison of inputs and outputs.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 100)\n",
    "    print(f\" {title}\")\n",
    "    print(\"=\" * 100)\n",
    "    print()\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        print(f\"[{idx + 1}] Input:  {row['input']}\")\n",
    "        print(f\"    Output: {row['output']}\")\n",
    "        print(f\"    Method: {row['method']} | Words: {row['word_count']}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Display all results\n",
    "display_comparison(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a styled DataFrame for better visualization\n",
    "display_df = results_df[['input', 'output', 'method']].copy()\n",
    "display_df.columns = ['Romanized Input', 'Kannada Output', 'Method']\n",
    "display_df.index = range(1, len(display_df) + 1)\n",
    "display_df.index.name = '#'\n",
    "\n",
    "# Display with styling\n",
    "display_df.style.set_properties(**{\n",
    "    'text-align': 'left',\n",
    "    'font-size': '14px'\n",
    "}).set_table_styles([\n",
    "    {'selector': 'th', 'props': [('font-size', '14px'), ('text-align', 'center')]}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Accuracy Calculation with Reference Translations\n",
    "\n",
    "We'll calculate accuracy by comparing transliteration output with known correct translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference translations (ground truth)\n",
    "reference_data = [\n",
    "    # (romanized, expected_kannada)\n",
    "    (\"namaskara\", \"ನಮಸ್ಕಾರ\"),\n",
    "    (\"hegidira\", \"ಹೇಗಿದೀರ\"),\n",
    "    (\"tumba\", \"ತುಂಬ\"),\n",
    "    (\"chennagide\", \"ಚೆನ್ನಾಗಿದೆ\"),\n",
    "    (\"olle\", \"ಒಳ್ಳೆ\"),\n",
    "    (\"olleya\", \"ಒಳ್ಳೆಯ\"),\n",
    "    (\"ketta\", \"ಕೆಟ್ಟ\"),\n",
    "    (\"bekilla\", \"ಬೇಕಿಲ್ಲ\"),\n",
    "    (\"beda\", \"ಬೇಡ\"),\n",
    "    (\"illa\", \"ಇಲ್ಲ\"),\n",
    "    (\"ide\", \"ಇದೆ\"),\n",
    "    (\"agide\", \"ಆಗಿದೆ\"),\n",
    "    (\"beku\", \"ಬೇಕು\"),\n",
    "    (\"gottu\", \"ಗೊತ್ತು\"),\n",
    "    (\"naanu\", \"ನಾನು\"),\n",
    "    (\"neenu\", \"ನೀನು\"),\n",
    "    (\"avaru\", \"ಅವರು\"),\n",
    "    (\"idu\", \"ಇದು\"),\n",
    "    (\"adu\", \"ಅದು\"),\n",
    "    (\"yenu\", \"ಯೇನು\"),\n",
    "    (\"elli\", \"ಎಲ್ಲಿ\"),\n",
    "    (\"hege\", \"ಹೇಗೆ\"),\n",
    "    (\"yaake\", \"ಯಾಕೆ\"),\n",
    "    (\"mattu\", \"ಮತ್ತು\"),\n",
    "    (\"aadare\", \"ಆದರೆ\"),\n",
    "    (\"santhosha\", \"ಸಂತೋಷ\"),\n",
    "    (\"dhanyavada\", \"ಧನ್ಯವಾದ\"),\n",
    "    (\"bengaluru\", \"ಬೆಂಗಳೂರು\"),\n",
    "    (\"kannada\", \"ಕನ್ನಡ\"),\n",
    "    (\"amma\", \"ಅಮ್ಮ\"),\n",
    "]\n",
    "\n",
    "print(f\"Reference data: {len(reference_data)} word pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(transliterator: Transliterator, \n",
    "                       reference_data: List[Tuple[str, str]]) -> Dict:\n",
    "    \"\"\"\n",
    "    Calculate transliteration accuracy against reference translations.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with accuracy metrics and detailed results.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    incorrect = []\n",
    "    results = []\n",
    "    \n",
    "    for romanized, expected in reference_data:\n",
    "        output, method = transliterator.transliterate_word(romanized)\n",
    "        is_correct = output == expected\n",
    "        \n",
    "        if is_correct:\n",
    "            correct += 1\n",
    "        else:\n",
    "            incorrect.append({\n",
    "                'input': romanized,\n",
    "                'expected': expected,\n",
    "                'got': output,\n",
    "                'method': method\n",
    "            })\n",
    "        \n",
    "        results.append({\n",
    "            'input': romanized,\n",
    "            'expected': expected,\n",
    "            'output': output,\n",
    "            'correct': is_correct,\n",
    "            'method': method\n",
    "        })\n",
    "    \n",
    "    total = len(reference_data)\n",
    "    accuracy = correct / total if total > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'total': total,\n",
    "        'correct': correct,\n",
    "        'incorrect': len(incorrect),\n",
    "        'accuracy': accuracy,\n",
    "        'accuracy_percent': f\"{accuracy * 100:.2f}%\",\n",
    "        'errors': incorrect,\n",
    "        'detailed_results': results\n",
    "    }\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_results = calculate_accuracy(transliterator, reference_data)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\" ACCURACY REPORT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total words tested: {accuracy_results['total']}\")\n",
    "print(f\"Correct: {accuracy_results['correct']}\")\n",
    "print(f\"Incorrect: {accuracy_results['incorrect']}\")\n",
    "print(f\"Accuracy: {accuracy_results['accuracy_percent']}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display detailed results as a DataFrame\n",
    "accuracy_df = pd.DataFrame(accuracy_results['detailed_results'])\n",
    "accuracy_df['status'] = accuracy_df['correct'].map({True: '✓', False: '✗'})\n",
    "\n",
    "# Show the results with styling\n",
    "def highlight_errors(row):\n",
    "    if row['correct']:\n",
    "        return ['background-color: #d4edda'] * len(row)\n",
    "    else:\n",
    "        return ['background-color: #f8d7da'] * len(row)\n",
    "\n",
    "styled_df = accuracy_df[['input', 'expected', 'output', 'status', 'method']].style.apply(\n",
    "    highlight_errors, axis=1\n",
    ")\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display errors in detail\n",
    "if accuracy_results['errors']:\n",
    "    print(\"\\nERROR DETAILS:\")\n",
    "    print(\"-\" * 70)\n",
    "    for error in accuracy_results['errors']:\n",
    "        print(f\"Input:    {error['input']}\")\n",
    "        print(f\"Expected: {error['expected']}\")\n",
    "        print(f\"Got:      {error['got']}\")\n",
    "        print(f\"Method:   {error['method']}\")\n",
    "        print(\"-\" * 70)\n",
    "else:\n",
    "    print(\"\\n✓ No errors! All transliterations matched expected output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Error Pattern Analysis\n",
    "\n",
    "Analyze patterns in transliteration errors to identify areas for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with words NOT in the fallback dictionary to analyze error patterns\n",
    "unknown_words = [\n",
    "    # Words likely NOT in fallback dict\n",
    "    (\"preetiya\", \"ಪ್ರೀತಿಯ\"),\n",
    "    (\"kathe\", \"ಕಥೆ\"),\n",
    "    (\"pustaka\", \"ಪುಸ್ತಕ\"),\n",
    "    (\"shale\", \"ಶಾಲೆ\"),\n",
    "    (\"makkalu\", \"ಮಕ್ಕಳು\"),\n",
    "    (\"hesaru\", \"ಹೆಸರು\"),\n",
    "    (\"kelasa\", \"ಕೆಲಸ\"),\n",
    "    (\"dina\", \"ದಿನ\"),\n",
    "    (\"samaya\", \"ಸಮಯ\"),\n",
    "    (\"jagat\", \"ಜಗತ್\"),\n",
    "    (\"vishaya\", \"ವಿಷಯ\"),\n",
    "    (\"karnataka\", \"ಕರ್ನಾಟಕ\"),\n",
    "    (\"bharata\", \"ಭಾರತ\"),\n",
    "    (\"cinema\", \"ಸಿನಿಮಾ\"),\n",
    "    (\"sangeetha\", \"ಸಂಗೀತ\"),\n",
    "]\n",
    "\n",
    "# Test these words\n",
    "unknown_results = calculate_accuracy(transliterator, unknown_words)\n",
    "\n",
    "print(\"Unknown Words Test Results:\")\n",
    "print(f\"Accuracy: {unknown_results['accuracy_percent']}\")\n",
    "print(f\"Words handled: {unknown_results['correct']}/{unknown_results['total']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_error_patterns(errors: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze error patterns in transliteration failures.\n",
    "    \"\"\"\n",
    "    if not errors:\n",
    "        return {'message': 'No errors to analyze'}\n",
    "    \n",
    "    patterns = {\n",
    "        'unchanged': [],  # Words returned as-is (not transliterated)\n",
    "        'partial': [],    # Words partially transliterated\n",
    "        'wrong': [],      # Words transliterated but incorrectly\n",
    "    }\n",
    "    \n",
    "    # Character patterns that often cause issues\n",
    "    problem_chars = Counter()\n",
    "    problem_endings = Counter()\n",
    "    \n",
    "    for error in errors:\n",
    "        input_word = error['input']\n",
    "        expected = error['expected']\n",
    "        got = error['got']\n",
    "        \n",
    "        # Categorize error type\n",
    "        if got == input_word:\n",
    "            patterns['unchanged'].append(error)\n",
    "        elif any(ord(c) >= 0x0C80 and ord(c) <= 0x0CFF for c in got):\n",
    "            patterns['wrong'].append(error)\n",
    "        else:\n",
    "            patterns['partial'].append(error)\n",
    "        \n",
    "        # Analyze problematic character patterns\n",
    "        for char in input_word:\n",
    "            problem_chars[char] += 1\n",
    "        \n",
    "        # Analyze word endings\n",
    "        if len(input_word) >= 2:\n",
    "            problem_endings[input_word[-2:]] += 1\n",
    "    \n",
    "    return {\n",
    "        'patterns': patterns,\n",
    "        'unchanged_count': len(patterns['unchanged']),\n",
    "        'partial_count': len(patterns['partial']),\n",
    "        'wrong_count': len(patterns['wrong']),\n",
    "        'common_problem_chars': problem_chars.most_common(10),\n",
    "        'common_problem_endings': problem_endings.most_common(5),\n",
    "    }\n",
    "\n",
    "# Analyze errors from unknown words test\n",
    "error_analysis = analyze_error_patterns(unknown_results['errors'])\n",
    "\n",
    "print(\"Error Pattern Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Unchanged (not transliterated): {error_analysis['unchanged_count']}\")\n",
    "print(f\"Partial transliteration: {error_analysis['partial_count']}\")\n",
    "print(f\"Wrong transliteration: {error_analysis['wrong_count']}\")\n",
    "print()\n",
    "print(\"Most common characters in failed words:\")\n",
    "for char, count in error_analysis['common_problem_chars'][:5]:\n",
    "    print(f\"  '{char}': {count} occurrences\")\n",
    "print()\n",
    "print(\"Most common endings in failed words:\")\n",
    "for ending, count in error_analysis['common_problem_endings']:\n",
    "    print(f\"  '{ending}': {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display unchanged words (these need to be added to fallback dict)\n",
    "if error_analysis['patterns']['unchanged']:\n",
    "    print(\"\\nWords that need to be added to fallback dictionary:\")\n",
    "    print(\"-\" * 60)\n",
    "    for error in error_analysis['patterns']['unchanged']:\n",
    "        print(f'    \"{error[\"input\"]}\": \"{error[\"expected\"]}\",')  # Ready to copy-paste!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create accuracy visualization\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    specs=[[{'type': 'pie'}, {'type': 'bar'}]],\n",
    "    subplot_titles=('Transliteration Accuracy', 'Error Types Distribution')\n",
    ")\n",
    "\n",
    "# Pie chart for overall accuracy\n",
    "labels = ['Correct', 'Incorrect']\n",
    "values = [accuracy_results['correct'], accuracy_results['incorrect']]\n",
    "colors = ['#28a745', '#dc3545']\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Pie(\n",
    "        labels=labels,\n",
    "        values=values,\n",
    "        marker_colors=colors,\n",
    "        hole=0.4,\n",
    "        textinfo='label+percent',\n",
    "        textposition='outside'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Bar chart for error types (from unknown words test)\n",
    "error_types = ['Unchanged', 'Partial', 'Wrong']\n",
    "error_counts = [\n",
    "    error_analysis['unchanged_count'],\n",
    "    error_analysis['partial_count'],\n",
    "    error_analysis['wrong_count']\n",
    "]\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=error_types,\n",
    "        y=error_counts,\n",
    "        marker_color=['#ffc107', '#17a2b8', '#dc3545'],\n",
    "        text=error_counts,\n",
    "        textposition='auto'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text='Transliteration Performance Analysis',\n",
    "    showlegend=False,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize method distribution\n",
    "method_counts = results_df['method'].value_counts()\n",
    "\n",
    "fig = px.pie(\n",
    "    values=method_counts.values,\n",
    "    names=method_counts.index,\n",
    "    title='Transliteration Method Distribution',\n",
    "    color_discrete_sequence=px.colors.qualitative.Set2,\n",
    "    hole=0.3\n",
    ")\n",
    "\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "fig.update_layout(height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize character frequency in test data\n",
    "all_chars = ''.join(test_samples).lower()\n",
    "char_freq = Counter(c for c in all_chars if c.isalpha())\n",
    "\n",
    "# Get top 15 characters\n",
    "top_chars = char_freq.most_common(15)\n",
    "\n",
    "fig = px.bar(\n",
    "    x=[c[0] for c in top_chars],\n",
    "    y=[c[1] for c in top_chars],\n",
    "    title='Character Frequency in Test Samples',\n",
    "    labels={'x': 'Character', 'y': 'Frequency'},\n",
    "    color=[c[1] for c in top_chars],\n",
    "    color_continuous_scale='Viridis'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='Character',\n",
    "    yaxis_title='Frequency',\n",
    "    height=400,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word length analysis\n",
    "results_df['input_length'] = results_df['input'].apply(len)\n",
    "results_df['output_length'] = results_df['output'].apply(len)\n",
    "\n",
    "fig = px.scatter(\n",
    "    results_df,\n",
    "    x='input_length',\n",
    "    y='output_length',\n",
    "    color='method',\n",
    "    size='word_count',\n",
    "    hover_data=['input', 'output'],\n",
    "    title='Input vs Output Length by Method',\n",
    "    labels={\n",
    "        'input_length': 'Input Length (chars)',\n",
    "        'output_length': 'Output Length (chars)',\n",
    "        'method': 'Method'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add diagonal line for reference\n",
    "max_len = max(results_df['input_length'].max(), results_df['output_length'].max())\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, max_len],\n",
    "        y=[0, max_len],\n",
    "        mode='lines',\n",
    "        line=dict(dash='dash', color='gray'),\n",
    "        name='1:1 ratio'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "print(\"=\" * 70)\n",
    "print(\" TRANSLITERATION MODEL TEST SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"CONFIGURATION:\")\n",
    "print(f\"  Model available: {transliterator.model_available}\")\n",
    "print(f\"  Fallback dictionary size: {len(transliterator.fallback_dict)} words\")\n",
    "print()\n",
    "print(\"ACCURACY METRICS:\")\n",
    "print(f\"  Known words accuracy: {accuracy_results['accuracy_percent']}\")\n",
    "print(f\"  Unknown words accuracy: {unknown_results['accuracy_percent']}\")\n",
    "print()\n",
    "print(\"ERROR ANALYSIS:\")\n",
    "print(f\"  Unchanged words: {error_analysis['unchanged_count']}\")\n",
    "print(f\"  Wrong translations: {error_analysis['wrong_count']}\")\n",
    "print()\n",
    "print(\"RECOMMENDATIONS:\")\n",
    "if error_analysis['unchanged_count'] > 0:\n",
    "    print(\"  1. Add missing words to fallback dictionary\")\n",
    "if not transliterator.model_available:\n",
    "    print(\"  2. Consider using Python 3.10 to enable IndicXlit model\")\n",
    "print(\"  3. Collect more training data for domain-specific words\")\n",
    "print(\"  4. Test with real user reviews for better coverage\")\n",
    "print()\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive testing cell - modify the text below to test your own inputs\n",
    "test_text = \"namaskara neevu hegidira tumba chennagide\"\n",
    "\n",
    "result = transliterator.transliterate(test_text)\n",
    "print(f\"Input:  {result.original}\")\n",
    "print(f\"Output: {result.transliterated}\")\n",
    "print(f\"Method: {result.method}\")\n",
    "print()\n",
    "print(\"Word mappings:\")\n",
    "for original, translated in result.word_mappings:\n",
    "    print(f\"  {original} → {translated}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
